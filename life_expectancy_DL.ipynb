{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "project_title",
   "metadata": {},
   "source": [
    "# Life Expectancy Prediction using Deep Learning\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements a deep learning model to predict life expectancy based on various health, economic, and social factors. The model uses a neural network built with TensorFlow/Keras to perform regression analysis on the WHO Life Expectancy dataset.\n",
    "\n",
    "## Dataset Information\n",
    "The dataset contains life expectancy data from the World Health Organization (WHO) with the following key features:\n",
    "- **Target Variable**: Life expectancy (in years)\n",
    "- **Features**: Various health indicators, economic factors, and demographic information\n",
    "- **Time Period**: Multiple years of data for different countries\n",
    "- **Data Type**: Mixed (numerical and categorical)\n",
    "\n",
    "## Methodology\n",
    "1. Data loading and exploration\n",
    "2. Data preprocessing and feature engineering\n",
    "3. Train-test split\n",
    "4. Feature scaling\n",
    "5. Neural network model creation\n",
    "6. Model training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_section",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "This section imports all necessary libraries for data manipulation, preprocessing, and deep learning model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb27d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning preprocessing and model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Deep learning framework (TensorFlow/Keras)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading_section",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load the Life Expectancy dataset from CSV file. This dataset contains information about life expectancy and various health/economic indicators for different countries over multiple years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea1978e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2938, 22)\n",
      "Columns: ['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', 'Income composition of resources', 'Schooling']\n",
      "\n",
      "Data types:\n",
      "Country                             object\n",
      "Year                                 int64\n",
      "Status                              object\n",
      "Life expectancy                    float64\n",
      "Adult Mortality                    float64\n",
      "infant deaths                        int64\n",
      "Alcohol                            float64\n",
      "percentage expenditure             float64\n",
      "Hepatitis B                        float64\n",
      "Measles                              int64\n",
      " BMI                               float64\n",
      "under-five deaths                    int64\n",
      "Polio                              float64\n",
      "Total expenditure                  float64\n",
      "Diphtheria                         float64\n",
      " HIV/AIDS                          float64\n",
      "GDP                                float64\n",
      "Population                         float64\n",
      " thinness  1-19 years              float64\n",
      " thinness 5-9 years                float64\n",
      "Income composition of resources    float64\n",
      "Schooling                          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from CSV file\n",
    "# Note: Make sure 'Life_Expectancy_Data.csv' is in the same directory as this notebook\n",
    "dataset = pd.read_csv('Life_Expectancy_Data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "print(f\"Columns: {list(dataset.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_exploration_section",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Examine the structure and content of the dataset to understand the features and identify any data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2dbbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
      "0  Afghanistan  2015  Developing              65.0            263.0   \n",
      "1  Afghanistan  2014  Developing              59.9            271.0   \n",
      "2  Afghanistan  2013  Developing              59.9            268.0   \n",
      "3  Afghanistan  2012  Developing              59.5            272.0   \n",
      "4  Afghanistan  2011  Developing              59.2            275.0   \n",
      "\n",
      "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
      "0             62     0.01               71.279624         65.0      1154  ...   \n",
      "1             64     0.01               73.523582         62.0       492  ...   \n",
      "2             66     0.01               73.219243         64.0       430  ...   \n",
      "3             69     0.01               78.184215         67.0      2787  ...   \n",
      "4             71     0.01                7.097109         68.0      3013  ...   \n",
      "\n",
      "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
      "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
      "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
      "2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n",
      "3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n",
      "4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n",
      "\n",
      "    thinness  1-19 years   thinness 5-9 years  \\\n",
      "0                   17.2                 17.3   \n",
      "1                   17.5                 17.5   \n",
      "2                   17.7                 17.7   \n",
      "3                   17.9                 18.0   \n",
      "4                   18.2                 18.2   \n",
      "\n",
      "   Income composition of resources  Schooling  \n",
      "0                            0.479       10.1  \n",
      "1                            0.476       10.0  \n",
      "2                            0.470        9.9  \n",
      "3                            0.463        9.8  \n",
      "4                            0.454        9.5  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Missing values per column:\n",
      "Country                              0\n",
      "Year                                 0\n",
      "Status                               0\n",
      "Life expectancy                     10\n",
      "Adult Mortality                     10\n",
      "infant deaths                        0\n",
      "Alcohol                            194\n",
      "percentage expenditure               0\n",
      "Hepatitis B                        553\n",
      "Measles                              0\n",
      " BMI                                34\n",
      "under-five deaths                    0\n",
      "Polio                               19\n",
      "Total expenditure                  226\n",
      "Diphtheria                          19\n",
      " HIV/AIDS                            0\n",
      "GDP                                448\n",
      "Population                         652\n",
      " thinness  1-19 years               34\n",
      " thinness 5-9 years                 34\n",
      "Income composition of resources    167\n",
      "Schooling                          163\n",
      "dtype: int64\n",
      "\n",
      "Basic statistical summary:\n",
      "              Year  Life expectancy   Adult Mortality  infant deaths  \\\n",
      "count  2938.000000       2928.000000      2928.000000    2938.000000   \n",
      "mean   2007.518720         69.224932       164.796448      30.303948   \n",
      "std       4.613841          9.523867       124.292079     117.926501   \n",
      "min    2000.000000         36.300000         1.000000       0.000000   \n",
      "25%    2004.000000         63.100000        74.000000       0.000000   \n",
      "50%    2008.000000         72.100000       144.000000       3.000000   \n",
      "75%    2012.000000         75.700000       228.000000      22.000000   \n",
      "max    2015.000000         89.000000       723.000000    1800.000000   \n",
      "\n",
      "           Alcohol  percentage expenditure  Hepatitis B       Measles   \\\n",
      "count  2744.000000             2938.000000  2385.000000    2938.000000   \n",
      "mean      4.602861              738.251295    80.940461    2419.592240   \n",
      "std       4.052413             1987.914858    25.070016   11467.272489   \n",
      "min       0.010000                0.000000     1.000000       0.000000   \n",
      "25%       0.877500                4.685343    77.000000       0.000000   \n",
      "50%       3.755000               64.912906    92.000000      17.000000   \n",
      "75%       7.702500              441.534144    97.000000     360.250000   \n",
      "max      17.870000            19479.911610    99.000000  212183.000000   \n",
      "\n",
      "              BMI   under-five deaths         Polio  Total expenditure  \\\n",
      "count  2904.000000         2938.000000  2919.000000         2712.00000   \n",
      "mean     38.321247           42.035739    82.550188            5.93819   \n",
      "std      20.044034          160.445548    23.428046            2.49832   \n",
      "min       1.000000            0.000000     3.000000            0.37000   \n",
      "25%      19.300000            0.000000    78.000000            4.26000   \n",
      "50%      43.500000            4.000000    93.000000            5.75500   \n",
      "75%      56.200000           28.000000    97.000000            7.49250   \n",
      "max      87.300000         2500.000000    99.000000           17.60000   \n",
      "\n",
      "       Diphtheria      HIV/AIDS            GDP    Population  \\\n",
      "count  2919.000000  2938.000000    2490.000000  2.286000e+03   \n",
      "mean     82.324084     1.742103    7483.158469  1.275338e+07   \n",
      "std      23.716912     5.077785   14270.169342  6.101210e+07   \n",
      "min       2.000000     0.100000       1.681350  3.400000e+01   \n",
      "25%      78.000000     0.100000     463.935626  1.957932e+05   \n",
      "50%      93.000000     0.100000    1766.947595  1.386542e+06   \n",
      "75%      97.000000     0.800000    5910.806335  7.420359e+06   \n",
      "max      99.000000    50.600000  119172.741800  1.293859e+09   \n",
      "\n",
      "        thinness  1-19 years   thinness 5-9 years  \\\n",
      "count            2904.000000          2904.000000   \n",
      "mean                4.839704             4.870317   \n",
      "std                 4.420195             4.508882   \n",
      "min                 0.100000             0.100000   \n",
      "25%                 1.600000             1.500000   \n",
      "50%                 3.300000             3.300000   \n",
      "75%                 7.200000             7.200000   \n",
      "max                27.700000            28.600000   \n",
      "\n",
      "       Income composition of resources    Schooling  \n",
      "count                      2771.000000  2775.000000  \n",
      "mean                          0.627551    11.992793  \n",
      "std                           0.210904     3.358920  \n",
      "min                           0.000000     0.000000  \n",
      "25%                           0.493000    10.100000  \n",
      "50%                           0.677000    12.300000  \n",
      "75%                           0.779000    14.300000  \n",
      "max                           0.948000    20.700000  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to understand the data structure\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(dataset.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# Basic statistical summary\n",
    "print(\"\\nBasic statistical summary:\")\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_preprocessing_section",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Clean and prepare the data for machine learning by handling missing values, removing unnecessary columns, and separating features from target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4479a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after preprocessing: (1649, 21)\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove 'Country' column as it's not useful for prediction\n",
    "# Country names are categorical identifiers that don't provide meaningful patterns for life expectancy prediction\n",
    "dataset = dataset.drop(['Country'], axis=1)\n",
    "\n",
    "# Handle missing values by dropping rows with NaN values\n",
    "# Note: In a production environment, you might want to use imputation instead\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "print(f\"Dataset shape after preprocessing: {dataset.shape}\")\n",
    "print(f\"Remaining missing values: {dataset.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e253c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1649, 20)\n",
      "Labels shape: (1649,)\n",
      "Target variable (Life expectancy) - Min: 4.20, Max: 20.70, Mean: 12.12\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "# The target variable 'Life expectancy' is in the last column\n",
    "labels = dataset.iloc[:, -1]  # Target variable: Life expectancy\n",
    "features = dataset.iloc[:, :-1]  # All other columns as features\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Target variable (Life expectancy) - Min: {labels.min():.2f}, Max: {labels.max():.2f}, Mean: {labels.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65bd74f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape after one-hot encoding: (1649, 20)\n",
      "Feature columns: ['Year', 'Life expectancy ', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', 'Income composition of resources', 'Status_Developing']\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical variables to dummy variables (one-hot encoding)\n",
    "# This is necessary for the neural network to process categorical data\n",
    "# The 'Status' column (Developed/Developing) will be converted to binary features\n",
    "features = pd.get_dummies(features, drop_first=True)  # drop_first=True to avoid multicollinearity\n",
    "\n",
    "print(f\"Features shape after one-hot encoding: {features.shape}\")\n",
    "print(f\"Feature columns: {list(features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_test_split_section",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "Split the dataset into training and testing sets to evaluate model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb615938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Features: (1319, 20), Labels: (1319,)\n",
      "Testing set - Features: (330, 20), Labels: (330,)\n",
      "Training set percentage: 80.0%\n",
      "Testing set percentage: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (80%) and testing (20%) sets\n",
    "# random_state=42 ensures reproducible results\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, \n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Training set - Features: {features_train.shape}, Labels: {labels_train.shape}\")\n",
    "print(f\"Testing set - Features: {features_test.shape}, Labels: {labels_test.shape}\")\n",
    "print(f\"Training set percentage: {len(features_train) / len(features) * 100:.1f}%\")\n",
    "print(f\"Testing set percentage: {len(features_test) / len(features) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_scaling_section",
   "metadata": {},
   "source": [
    "## 6. Feature Scaling\n",
    "\n",
    "Scale numerical features to ensure all features contribute equally to the model training. This is crucial for neural networks as they are sensitive to the scale of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4a4d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns to be scaled: ['Year', 'Life expectancy ', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', 'Income composition of resources']\n",
      "Number of numerical features: 19\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical features for scaling\n",
    "# Neural networks perform better when features are on similar scales\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns\n",
    "\n",
    "# Create a ColumnTransformer to scale only numerical features\n",
    "# StandardScaler normalizes features to have mean=0 and std=1\n",
    "ct = ColumnTransformer(\n",
    "    [(\"numeric_scaler\", StandardScaler(), numerical_columns)], \n",
    "    remainder='passthrough'  # Keep non-numerical features as-is\n",
    ")\n",
    "\n",
    "print(f\"Numerical columns to be scaled: {list(numerical_columns)}\")\n",
    "print(f\"Number of numerical features: {len(numerical_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03efb32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled training features shape: (1319, 20)\n",
      "Scaled testing features shape: (330, 20)\n",
      "\n",
      "Training data statistics after scaling:\n",
      "Mean of first few features: [-1.12426284e-14 -1.51104805e-15 -1.21207063e-17 -2.69349028e-17\n",
      " -9.69656501e-17]\n",
      "Std of first few features: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Apply scaling to training and testing sets\n",
    "# IMPORTANT: Fit the scaler only on training data to prevent data leakage\n",
    "features_train_scaled = ct.fit_transform(features_train)  # Fit and transform training data\n",
    "features_test_scaled = ct.transform(features_test)        # Only transform test data (using training stats)\n",
    "\n",
    "print(f\"Scaled training features shape: {features_train_scaled.shape}\")\n",
    "print(f\"Scaled testing features shape: {features_test_scaled.shape}\")\n",
    "\n",
    "# Verify scaling worked correctly (training data should have mean≈0, std≈1 for numerical features)\n",
    "print(f\"\\nTraining data statistics after scaling:\")\n",
    "print(f\"Mean of first few features: {np.mean(features_train_scaled[:, :5], axis=0)}\")\n",
    "print(f\"Std of first few features: {np.std(features_train_scaled[:, :5], axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_creation_section",
   "metadata": {},
   "source": [
    "## 7. Neural Network Model Creation\n",
    "\n",
    "Build a deep learning model using TensorFlow/Keras. The model architecture consists of:\n",
    "- Input layer: Accepts features from the dataset\n",
    "- Hidden layer: 64 neurons with ReLU activation for non-linearity\n",
    "- Output layer: Single neuron for regression (predicting life expectancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9163fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,409\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,409\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Details:\n",
      "- Input features: 20\n",
      "- Hidden layer neurons: 64\n",
      "- Output: 1 (life expectancy prediction)\n",
      "- Total parameters: 1409\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model (layers stacked one after another)\n",
    "my_model = Sequential()\n",
    "\n",
    "# Input layer: defines the shape of input data\n",
    "# The input shape should match the number of features after preprocessing\n",
    "input_layer = InputLayer(input_shape=(features_train_scaled.shape[1],))\n",
    "my_model.add(input_layer)\n",
    "\n",
    "# Hidden layer: 64 neurons with ReLU activation\n",
    "# ReLU (Rectified Linear Unit) is commonly used for hidden layers\n",
    "# It helps with the vanishing gradient problem and is computationally efficient\n",
    "my_model.add(Dense(64, activation='relu', name='hidden_layer'))\n",
    "\n",
    "# Output layer: Single neuron for regression (no activation function)\n",
    "# For regression tasks, we don't use activation in the output layer\n",
    "# This allows the model to output any real number (life expectancy in years)\n",
    "my_model.add(Dense(1, name='output_layer'))\n",
    "\n",
    "# Display model architecture\n",
    "print(\"Model Architecture:\")\n",
    "my_model.summary()\n",
    "\n",
    "print(f\"\\nModel Details:\")\n",
    "print(f\"- Input features: {features_train_scaled.shape[1]}\")\n",
    "print(f\"- Hidden layer neurons: 64\")\n",
    "print(f\"- Output: 1 (life expectancy prediction)\")\n",
    "print(f\"- Total parameters: {my_model.count_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_training_section",
   "metadata": {},
   "source": [
    "## 8. Model Compilation and Training\n",
    "\n",
    "Configure the model for training by specifying:\n",
    "- **Loss function**: Mean Squared Error (MSE) - appropriate for regression tasks\n",
    "- **Optimizer**: Adam - adaptive learning rate optimizer that works well for most problems\n",
    "- **Metrics**: Mean Absolute Error (MAE) - easier to interpret than MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94491532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully!\n",
      "Optimizer: Adam with learning rate 0.0010000000474974513\n",
      "Loss function: Mean Squared Error (MSE)\n",
      "Metrics: Mean Absolute Error (MAE)\n",
      "\n",
      "Starting model training...\n",
      "Epoch 1/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 155.7377 - mae: 12.1236 - val_loss: 126.7375 - val_mae: 10.9554\n",
      "Epoch 2/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 122.7278 - mae: 10.7929 - val_loss: 97.6267 - val_mae: 9.5963\n",
      "Epoch 3/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 91.6700 - mae: 9.2940 - val_loss: 69.4931 - val_mae: 8.0312\n",
      "Epoch 4/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 63.7902 - mae: 7.7100 - val_loss: 44.8274 - val_mae: 6.3308\n",
      "Epoch 5/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.6819 - mae: 5.9386 - val_loss: 26.8880 - val_mae: 4.6987\n",
      "Epoch 6/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23.5009 - mae: 4.3245 - val_loss: 16.2982 - val_mae: 3.4559\n",
      "Epoch 7/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.5830 - mae: 3.1479 - val_loss: 10.9974 - val_mae: 2.7623\n",
      "Epoch 8/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0771 - mae: 2.4351 - val_loss: 8.5674 - val_mae: 2.3917\n",
      "Epoch 9/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8767 - mae: 2.2585 - val_loss: 7.2214 - val_mae: 2.1711\n",
      "Epoch 10/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6393 - mae: 2.0744 - val_loss: 6.5072 - val_mae: 2.0334\n",
      "Epoch 11/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9213 - mae: 1.9395 - val_loss: 5.9891 - val_mae: 1.9330\n",
      "Epoch 12/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8818 - mae: 1.7784 - val_loss: 5.6156 - val_mae: 1.8542\n",
      "Epoch 13/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9295 - mae: 1.7420 - val_loss: 5.2758 - val_mae: 1.7879\n",
      "Epoch 14/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8285 - mae: 1.7395 - val_loss: 5.0118 - val_mae: 1.7309\n",
      "Epoch 15/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4364 - mae: 1.6615 - val_loss: 4.8012 - val_mae: 1.6828\n",
      "Epoch 16/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8024 - mae: 1.5316 - val_loss: 4.6277 - val_mae: 1.6455\n",
      "Epoch 17/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4739 - mae: 1.4810 - val_loss: 4.4367 - val_mae: 1.6065\n",
      "Epoch 18/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9994 - mae: 1.5554 - val_loss: 4.2803 - val_mae: 1.5720\n",
      "Epoch 19/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4630 - mae: 1.4637 - val_loss: 4.1478 - val_mae: 1.5413\n",
      "Epoch 20/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1743 - mae: 1.4019 - val_loss: 4.0477 - val_mae: 1.5168\n",
      "Epoch 21/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6365 - mae: 1.4855 - val_loss: 3.9039 - val_mae: 1.4884\n",
      "Epoch 22/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2265 - mae: 1.3914 - val_loss: 3.8117 - val_mae: 1.4697\n",
      "Epoch 23/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2365 - mae: 1.3903 - val_loss: 3.7103 - val_mae: 1.4453\n",
      "Epoch 24/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8388 - mae: 1.3275 - val_loss: 3.6237 - val_mae: 1.4291\n",
      "Epoch 25/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8085 - mae: 1.3281 - val_loss: 3.5233 - val_mae: 1.4076\n",
      "Epoch 26/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8842 - mae: 1.3136 - val_loss: 3.4197 - val_mae: 1.3895\n",
      "Epoch 27/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7312 - mae: 1.2988 - val_loss: 3.3814 - val_mae: 1.3785\n",
      "Epoch 28/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8175 - mae: 1.3129 - val_loss: 3.2639 - val_mae: 1.3587\n",
      "Epoch 29/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6688 - mae: 1.2750 - val_loss: 3.1875 - val_mae: 1.3419\n",
      "Epoch 30/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3434 - mae: 1.2064 - val_loss: 3.1197 - val_mae: 1.3289\n",
      "Epoch 31/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5983 - mae: 1.2735 - val_loss: 3.0397 - val_mae: 1.3123\n",
      "Epoch 32/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3390 - mae: 1.1939 - val_loss: 2.9684 - val_mae: 1.2984\n",
      "Epoch 33/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4497 - mae: 1.2125 - val_loss: 2.8783 - val_mae: 1.2844\n",
      "Epoch 34/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3649 - mae: 1.1809 - val_loss: 2.8389 - val_mae: 1.2759\n",
      "Epoch 35/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1854 - mae: 1.1449 - val_loss: 2.7609 - val_mae: 1.2580\n",
      "Epoch 36/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1288 - mae: 1.1560 - val_loss: 2.7097 - val_mae: 1.2527\n",
      "Epoch 37/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0819 - mae: 1.1419 - val_loss: 2.6542 - val_mae: 1.2419\n",
      "Epoch 38/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1751 - mae: 1.1459 - val_loss: 2.5820 - val_mae: 1.2254\n",
      "Epoch 39/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1433 - mae: 1.1451 - val_loss: 2.5308 - val_mae: 1.2142\n",
      "Epoch 40/40\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0133 - mae: 1.1047 - val_loss: 2.4928 - val_mae: 1.2035\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Configure the optimizer with an appropriate learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with:\n",
    "# - MSE (Mean Squared Error) loss: standard for regression problems\n",
    "# - MAE (Mean Absolute Error) metric: easier to interpret (average error in years)\n",
    "my_model.compile(\n",
    "    loss='mse',           # Loss function for regression\n",
    "    metrics=['mae'],      # Additional metrics to monitor\n",
    "    optimizer=optimizer   # Optimization algorithm\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Optimizer: Adam with learning rate {optimizer.learning_rate.numpy()}\")\n",
    "print(f\"Loss function: Mean Squared Error (MSE)\")\n",
    "print(f\"Metrics: Mean Absolute Error (MAE)\")\n",
    "\n",
    "# Train the model with improved parameters\n",
    "# - epochs=40: More training iterations for better convergence\n",
    "# - batch_size=32: Better than batch_size=1, provides more stable gradients\n",
    "# - validation_split=0.2: Use 20% of training data for validation during training\n",
    "print(\"\\nStarting model training...\")\n",
    "history = my_model.fit(\n",
    "    features_train_scaled, labels_train,\n",
    "    epochs=40,              # Number of training epochs\n",
    "    batch_size=32,          # Number of samples per gradient update\n",
    "    validation_split=0.2,   # Use 20% of training data for validation\n",
    "    verbose=1               # Show progress during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_evaluation_section",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set to assess its performance on unseen data. This gives us an unbiased estimate of how well the model will perform in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "model_evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n",
      "\n",
      "=== Model Performance on Test Set ===\n",
      "Test Loss (MSE): 2.2009\n",
      "Test MAE: 1.1621 years\n",
      "Test RMSE: 1.4835 years\n",
      "\n",
      "=== Additional Metrics ===\n",
      "R² Score: 0.7035 (closer to 1.0 is better)\n",
      "MAPE: 0.1055 (10.55%)\n",
      "\n",
      "=== Sample Predictions vs Actual Values ===\n",
      "Predicted: 11.29 years, Actual: 11.00 years, Difference: 0.29 years\n",
      "Predicted: 14.94 years, Actual: 13.50 years, Difference: 1.44 years\n",
      "Predicted: 15.12 years, Actual: 16.40 years, Difference: 1.28 years\n",
      "Predicted: 10.07 years, Actual: 10.10 years, Difference: 0.03 years\n",
      "Predicted: 8.15 years, Actual: 6.40 years, Difference: 1.75 years\n",
      "Predicted: 10.31 years, Actual: 9.60 years, Difference: 0.71 years\n",
      "Predicted: 12.71 years, Actual: 12.50 years, Difference: 0.21 years\n",
      "Predicted: 12.09 years, Actual: 13.20 years, Difference: 1.11 years\n",
      "Predicted: 15.80 years, Actual: 16.50 years, Difference: 0.70 years\n",
      "Predicted: 11.90 years, Actual: 11.60 years, Difference: 0.30 years\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_loss, test_mae = my_model.evaluate(features_test_scaled, labels_test, verbose=0)\n",
    "\n",
    "print(f\"\\n=== Model Performance on Test Set ===\")\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f} years\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_loss):.4f} years\")\n",
    "\n",
    "# Make predictions on test set for further analysis\n",
    "predictions = my_model.predict(features_test_scaled, verbose=0)\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "r2 = r2_score(labels_test, predictions)\n",
    "mape = mean_absolute_percentage_error(labels_test, predictions)\n",
    "\n",
    "print(f\"\\n=== Additional Metrics ===\")\n",
    "print(f\"R² Score: {r2:.4f} (closer to 1.0 is better)\")\n",
    "print(f\"MAPE: {mape:.4f} ({mape*100:.2f}%)\")\n",
    "\n",
    "# Show some example predictions vs actual values\n",
    "print(f\"\\n=== Sample Predictions vs Actual Values ===\")\n",
    "for i in range(min(10, len(predictions))):\n",
    "    print(f\"Predicted: {predictions[i][0]:.2f} years, Actual: {labels_test.iloc[i]:.2f} years, Difference: {abs(predictions[i][0] - labels_test.iloc[i]):.2f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions_section",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Next Steps\n",
    "\n",
    "### Model Performance Interpretation:\n",
    "- **MAE (Mean Absolute Error)**: Average prediction error in years\n",
    "- **RMSE (Root Mean Square Error)**: Penalizes larger errors more heavily\n",
    "- **R² Score**: Proportion of variance explained by the model (0-1, higher is better)\n",
    "- **MAPE**: Mean Absolute Percentage Error, shows error as a percentage\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Feature Engineering**: Create new features or transform existing ones\n",
    "2. **Hyperparameter Tuning**: Optimize learning rate, batch size, number of neurons\n",
    "3. **Model Architecture**: Try different numbers of layers or neurons\n",
    "4. **Regularization**: Add dropout or L1/L2 regularization to prevent overfitting\n",
    "5. **Data Quality**: Handle missing values more sophisticatedly (imputation)\n",
    "6. **Cross-Validation**: Use k-fold cross-validation for more robust evaluation\n",
    "\n",
    "### Usage Notes:\n",
    "- This model predicts life expectancy based on health and socioeconomic indicators\n",
    "- The predictions should be interpreted as estimates with inherent uncertainty\n",
    "- Regular retraining with updated data would improve model accuracy over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
